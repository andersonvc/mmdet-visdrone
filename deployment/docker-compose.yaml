services:

  #trainer:
  #  build: train_image
  #  depends_on:
  #    - mlflow_server
  #  env_file:
  #    - train_image/local.env
  #  environment:
  #    - MLFLOW_DATABASE_URI=${MLFLOW_DATABASE_URI}
  #  extra_hosts:
  #    - host.docker.internal:172.17.0.1
  #  shm_size: 2gb
  #  volumes:
  #    - ${BASE_DIR}/configs:/app/configs
  #    - ${BASE_DIR}/visdrone:/app/visdrone
  #    - ${MLFLOW_BASE_DIR}:/app/mlruns
  #    - ${MLFLOW_DATA_DIR}:/data
  #    - ${MLFLOW_DATA_DIR}/default_models:/root/.cache/torch/hub/checkpoints

  mlflow_database:
    build: mlflow_database_image
    environment:
      - MLFLOW_DATABASE_PASSWORD=${MLFLOW_DATABASE_PASSWORD}
      - AIRFLOW_DATABASE_PASSWORD=${AIRFLOW_DATABASE_PASSWORD}
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    ports:
      - 5432:5432
    extra_hosts:
      - host.docker.internal:172.17.0.1
    volumes:
      - ${MLFLOW_DATABASE}:/var/lib/postgresql/data

  mlflow_server:
    build: mlflow_server_image
    depends_on:
      - mlflow_database
    environment:
      - MLFLOW_DATABASE_URI=${MLFLOW_DATABASE_URI}
    ports:
      - 5000:5000
    extra_hosts:
      - host.docker.internal:172.17.0.1
    volumes:
      - ${MLFLOW_BASE_DIR}:/app/mlruns
  
  airflow:
    build: airflow_image
    restart: always
    depends_on:
        - mlflow_database
    environment:
        - LOAD_EX=n
        - EXECUTOR=Local
        - POSTGRES_HOST=172.17.0.1
        - POSTGRES_USER=airflow
        - POSTGRES_PASSWORD=${AIRFLOW_DATABASE_PASSWORD}
        - POSTGRES_DB=airflow
    extra_hosts:
      - host.docker.internal:172.17.0.1
    logging:
        options:
            max-size: 10m
            max-file: "3"
    volumes:
        - ${AIRFLOW_BASE_DIR}/dags:/usr/local/airflow/dags
        - ${AIRFLOW_BASE_DIR}/plugins:/usr/local/airflow/plugins
    ports:
        - 8080:8080
    command: webserver
    healthcheck:
        test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
        interval: 30s
        timeout: 30s
        retries: 3